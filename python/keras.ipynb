{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/guide/keras/train_and_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import exists\n",
    "\n",
    "# force re-import if changes are made to the import functions\n",
    "import importlib\n",
    "\n",
    "import read_input_data\n",
    "importlib.reload(read_input_data)\n",
    "from read_input_data import *\n",
    "import neural_network\n",
    "importlib.reload(neural_network)\n",
    "from neural_network import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "hidden_1 = layers.Dense(50, activation='sigmoid', name=\"dense_1\")(inputs)\n",
    "outputs = layers.Dense(10, activation='sigmoid', name=\"predictions\")(hidden_1)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train_k, y_train_k), (x_test_k, y_test_k) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "x_train_k = x_train_k.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test_k = x_test_k.reshape(10000, 784).astype(\"float32\") / 255\n",
    "\n",
    "y_train_k = y_train_k.astype(\"float32\")\n",
    "y_test_k = y_test_k.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val_k = x_train_k[-10000:]\n",
    "y_val_k = y_train_k[-10000:]\n",
    "x_train_k = x_train_k[:-10000]\n",
    "y_train_k = y_train_k[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_m, y_train_m = read_kaggle_data_all_into_training_for_keras('E:/Code/kaggle/digits/data/train_95.csv')\n",
    "x_test_m, y_test_m = read_kaggle_data_all_into_training_for_keras('E:/Code/kaggle/digits/data/test_05.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.1509 - sparse_categorical_accuracy: 0.9560 - val_loss: 0.1601 - val_sparse_categorical_accuracy: 0.9529\n",
      "Epoch 2/5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.1401 - sparse_categorical_accuracy: 0.9599 - val_loss: 0.1527 - val_sparse_categorical_accuracy: 0.9557\n",
      "Epoch 3/5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.1306 - sparse_categorical_accuracy: 0.9624 - val_loss: 0.1530 - val_sparse_categorical_accuracy: 0.9552\n",
      "Epoch 4/5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.1225 - sparse_categorical_accuracy: 0.9647 - val_loss: 0.1443 - val_sparse_categorical_accuracy: 0.9586\n",
      "Epoch 5/5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.1154 - sparse_categorical_accuracy: 0.9670 - val_loss: 0.1382 - val_sparse_categorical_accuracy: 0.9610\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x_train_m,\n",
    "    y_train_m,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_test_m, y_test_m),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1382 - sparse_categorical_accuracy: 0.9610\n",
      "test loss, test acc: [0.13824784755706787, 0.9609524011611938]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test_m, y_test_m, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train_m, y_train_m))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test_m, y_test_m))\n",
    "test_dataset = test_dataset.batch(64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.0473 - sparse_categorical_accuracy: 0.9877 - val_loss: 0.1135 - val_sparse_categorical_accuracy: 0.9719\n",
      "Epoch 2/5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.0458 - sparse_categorical_accuracy: 0.9880 - val_loss: 0.1124 - val_sparse_categorical_accuracy: 0.9695\n",
      "Epoch 3/5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.0443 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.1133 - val_sparse_categorical_accuracy: 0.9695\n",
      "Epoch 4/5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.0429 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.1155 - val_sparse_categorical_accuracy: 0.9690\n",
      "Epoch 5/5\n",
      "624/624 [==============================] - 4s 6ms/step - loss: 0.0417 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.1140 - val_sparse_categorical_accuracy: 0.9719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25e908c9690>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset, epochs=5, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2ab2034122c39472c56901cfa84dd49cdbabb04de34f4eea7c7aca03b70e790"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
